{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ML_working ","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNU6AB5JDHYUEbfxY1jqIXm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":59,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":480},"id":"SdGtSdp8fYaO","executionInfo":{"status":"error","timestamp":1640286830170,"user_tz":-330,"elapsed":21590,"user":{"displayName":"Diksha Jena (B20CS013)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03488940742474601522"}},"outputId":"8bdc9808-ef02-4d0c-f360-94bcb6bde629"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: keras==1.1.0 in /usr/local/lib/python3.7/dist-packages (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from keras==1.1.0) (1.15.0)\n","Requirement already satisfied: theano in /usr/local/lib/python3.7/dist-packages (from keras==1.1.0) (0.9.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==1.1.0) (3.13)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from theano->keras==1.1.0) (1.19.5)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from theano->keras==1.1.0) (1.4.1)\n","\u001b[33mWARNING: Skipping theanos as it is not installed.\u001b[0m\n","Requirement already satisfied: theano==0.9.0 in /usr/local/lib/python3.7/dist-packages (0.9.0)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from theano==0.9.0) (1.19.5)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from theano==0.9.0) (1.15.0)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from theano==0.9.0) (1.4.1)\n","\u001b[31mERROR: Could not find a version that satisfies the requirement opencv-python==3.0.0 (from versions: 3.4.0.14, 3.4.2.17, 3.4.3.18, 3.4.4.19, 3.4.5.20, 3.4.6.27, 3.4.7.28, 3.4.8.29, 3.4.9.31, 3.4.9.33, 3.4.10.35, 3.4.10.37, 3.4.11.39, 3.4.11.41, 3.4.11.43, 3.4.11.45, 3.4.13.47, 3.4.14.51, 3.4.14.53, 3.4.15.55, 3.4.16.57, 3.4.16.59, 4.0.0.21, 4.0.1.23, 4.0.1.24, 4.1.0.25, 4.1.1.26, 4.1.2.30, 4.2.0.32, 4.2.0.34, 4.3.0.36, 4.3.0.38, 4.4.0.40, 4.4.0.42, 4.4.0.44, 4.4.0.46, 4.5.1.48, 4.5.2.52, 4.5.2.54, 4.5.3.56, 4.5.4.58, 4.5.4.60)\u001b[0m\n","\u001b[31mERROR: No matching distribution found for opencv-python==3.0.0\u001b[0m\n","Requirement already satisfied: pyblas in /usr/local/lib/python3.7/dist-packages (0.0.10)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyblas) (1.19.5)\n"]},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-59-3f8316a243e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_image_dim_ordering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'th'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: module 'keras.backend' has no attribute 'set_image_dim_ordering'"]}],"source":["!pip install keras==1.1.0\n","!pip uninstall theanos\n","!pip install theano==0.9.0\n","!pip install opencv-python==3.0.0\n","!pip install pyblas\n","\n","import os\n","\n","os.environ[\"KERAS_BACKEND\"] = \"theano\"\n","\n","import keras.backend\n","keras.backend.set_image_dim_ordering('th')"]},{"cell_type":"code","source":[""],"metadata":{"id":"3K9D89jNtRhJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from __future__ import division\n","from tensorflow.keras.optimizers import RMSprop\n","from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n","from keras.layers import Input\n","from keras.models import Model\n","import os, cv2, sys\n","import numpy as np"],"metadata":{"id":"tZBE1MhCfhzB","executionInfo":{"status":"ok","timestamp":1640283242093,"user_tz":-330,"elapsed":531,"user":{"displayName":"Diksha Jena (B20CS013)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03488940742474601522"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["x = Input((3, 240, 320))\n","x_maps = Input((16, 30, 40))"],"metadata":{"id":"44DcXbaift9y","executionInfo":{"status":"ok","timestamp":1640283338187,"user_tz":-330,"elapsed":2,"user":{"displayName":"Diksha Jena (B20CS013)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03488940742474601522"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["from __future__ import division\n","from keras.layers import Lambda, merge\n","from keras.layers.convolutional import Conv2D, MaxPooling2D\n","import keras.backend as K\n","import theano.tensor as T\n","from __future__ import print_function\n","from __future__ import absolute_import\n","from keras.utils.data_utils import get_file"],"metadata":{"id":"oFXWXo30gjpK","executionInfo":{"status":"ok","timestamp":1640283961243,"user_tz":-330,"elapsed":2,"user":{"displayName":"Diksha Jena (B20CS013)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03488940742474601522"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["TH_WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_th_dim_ordering_th_kernels_notop.h5'\n","\n","\n","def dcn_vgg(input_tensor=None):\n","    input_shape = (3, None, None)\n","\n","    if input_tensor is None:\n","        img_input = Input(shape=input_shape)\n","    else:\n","        if not K.is_keras_tensor(input_tensor):\n","            img_input = Input(tensor=input_tensor, shape=input_shape)\n","        else:\n","            img_input = input_tensor\n","\n","    # conv_1\n","    x = Conv2D(64, 3, 3, activation='relu', padding='same', name='block1_conv1')(img_input)\n","    x = Conv2D(64, 3, 3, activation='relu', padding='same', name='block1_conv2')(x)\n","    x = MaxPooling2D((2, 2), strides=(2, 2), data_format=\"channels_first\", name='block1_pool')(x)\n","\n","    # conv_2\n","    x = Conv2D(128, 3, 3, activation='relu', padding='same', name='block2_conv1')(x)\n","    x = Conv2D(128, 3, 3, activation='relu', padding='same', name='block2_conv2')(x)\n","    x = MaxPooling2D((2, 2), strides=(2, 2),  data_format=\"channels_first\",name='block2_pool')(x)\n","\n","    # conv_3\n","    x = Conv2D(256, 3, 3, activation='relu', padding='same', name='block3_conv1')(x)\n","    x = Conv2D(256, 3, 3, activation='relu', padding='same', name='block3_conv2')(x)\n","    x = Conv2D(256, 3, 3, activation='relu', padding='same', name='block3_conv3')(x)\n","    x = MaxPooling2D((2, 2), strides=(2, 2),  data_format=\"channels_first\",name='block3_pool', padding='same')(x)\n","\n","    # conv_4\n","    x = Conv2D(512, 3, 3, activation='relu', padding='same', name='block4_conv1')(x)\n","    x = Conv2D(512, 3, 3, activation='relu', padding='same', name='block4_conv2')(x)\n","    x = Conv2D(512, 3, 3, activation='relu', padding='same', name='block4_conv3')(x)\n","    x = MaxPooling2D((2, 2), strides=(1, 1), data_format=\"channels_first\", name='block4_pool', padding='same')(x)\n","\n","    # conv_5\n","    x = Conv2D(512, 1, 1, activation='relu', padding='same', name='block5_conv1', dilation_rate=(2, 2))(x)\n","    x = Conv2D(512, 1, 1, activation='relu', padding='same', name='block5_conv2', dilation_rate=(2, 2))(x)\n","    x = Conv2D(512, 1, 1, activation='relu', padding='same', name='block5_conv3', dilation_rate=(2, 2))(x)\n","\n","    # Create model\n","    model = Model(img_input, x)\n","\n","    # Load weights\n","    weights_path = get_file('vgg16_weights_th_dim_ordering_th_kernels_notop.h5', TH_WEIGHTS_PATH_NO_TOP,\n","                            cache_subdir='models')\n","    model.load_weights(weights_path)\n","\n","    return model"],"metadata":{"id":"a6gwkuw6iZmk","executionInfo":{"status":"ok","timestamp":1640288442839,"user_tz":-330,"elapsed":415,"user":{"displayName":"Diksha Jena (B20CS013)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03488940742474601522"}}},"execution_count":64,"outputs":[]},{"cell_type":"markdown","source":["##hide"],"metadata":{"id":"fKwIg-9-xMNr"}},{"cell_type":"code","source":["def gaussian_priors_init(shape, name=None):\n","    means = np.random.uniform(low=0.3, high=0.7, size=shape[0] // 2)\n","    covars = np.random.uniform(low=0.05, high=0.3, size=shape[0] // 2)\n","    return K.variable(np.concatenate((means, covars), axis=0), name=name)"],"metadata":{"id":"x7bZBbkujpjx","executionInfo":{"status":"ok","timestamp":1640285258497,"user_tz":-330,"elapsed":2,"user":{"displayName":"Diksha Jena (B20CS013)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03488940742474601522"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["def repeat(x):\n","    return K.reshape(K.repeat(K.batch_flatten(x), 4), (1, 4, 512, 30, 40))\n","\n","\n","def repeat_shape(s):\n","    return (s[0], 4) + s[1:]\n","\n","\n","def upsampling(x):\n","    return T.nnet.abstract_conv.bilinear_upsampling(input=x, ratio=16, num_input_channels=1, batch_size=1)\n","\n","\n","def upsampling_shape(s):\n","    return s[:2] + (s[2] * 16, s[3] * 16)\n"],"metadata":{"id":"ZBtYrYpIkMd4","executionInfo":{"status":"ok","timestamp":1640285261257,"user_tz":-330,"elapsed":704,"user":{"displayName":"Diksha Jena (B20CS013)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03488940742474601522"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["from keras.layers import Layer, InputSpec\n","from keras import initializers, regularizers, constraints\n","import theano\n","import numpy as np\n","floatX = theano.config.floatX\n","\n","\n","class LearningPrior(Layer):\n","    def __init__(self, nb_gaussian, init='normal', weights=None,\n","                 W_regularizer=None, activity_regularizer=None,\n","                 W_constraint=None, **kwargs):\n","        self.nb_gaussian = nb_gaussian\n","        self.init = initializers.get(init, dim_ordering='th')\n","\n","        self.W_regularizer = regularizers.get(W_regularizer)\n","        self.activity_regularizer = regularizers.get(activity_regularizer)\n","\n","        self.W_constraint = constraints.get(W_constraint)\n","\n","        self.input_spec = [InputSpec(ndim=4)]\n","        self.initial_weights = weights\n","        super(LearningPrior, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        self.W_shape = (self.nb_gaussian*4, )\n","        self.W = self.init(self.W_shape, name='{}_W'.format(self.name))\n","\n","        self.trainable_weights = [self.W]\n","\n","        self.regularizers = []\n","        if self.W_regularizer:\n","            self.W_regularizer.set_param(self.W)\n","            self.regularizers.append(self.W_regularizer)\n","\n","        if self.activity_regularizer:\n","            self.activity_regularizer.set_layer(self)\n","            self.regularizers.append(self.activity_regularizer)\n","\n","        if self.initial_weights is not None:\n","            self.set_weights(self.initial_weights)\n","            del self.initial_weights\n","\n","        self.constraints = {}\n","        if self.W_constraint:\n","            self.constraints[self.W] = self.W_constraint\n","\n","    def get_output_shape_for(self, input_shape):\n","        self.b_s = input_shape[0]\n","        self.height = input_shape[2]\n","        self.width = input_shape[3]\n","\n","        return self.b_s, self.nb_gaussian, self.height, self.width\n","\n","    def call(self, x, mask=None):\n","        mu_x = self.W[:self.nb_gaussian]\n","        mu_y = self.W[self.nb_gaussian:self.nb_gaussian*2]\n","        sigma_x = self.W[self.nb_gaussian*2:self.nb_gaussian*3]\n","        sigma_y = self.W[self.nb_gaussian*3:]\n","\n","        self.b_s = x.shape[0]\n","        self.height = x.shape[2]\n","        self.width = x.shape[3]\n","\n","        e = self.height / self.width\n","        e1 = (1 - e) / 2\n","        e2 = e1 + e\n","\n","        mu_x = K.clip(mu_x, 0.25, 0.75)\n","        mu_y = K.clip(mu_y, 0.35, 0.65)\n","\n","        sigma_x = K.clip(sigma_x, 0.1, 0.9)\n","        sigma_y = K.clip(sigma_y, 0.2, 0.8)\n","\n","        x_t = T.dot(T.ones((self.height, 1)), self._linspace(0, 1.0, self.width).dimshuffle('x', 0))\n","        y_t = T.dot(self._linspace(e1, e2, self.height).dimshuffle(0, 'x'), T.ones((1, self.width)))\n","\n","        x_t = K.repeat_elements(K.expand_dims(x_t, dim=-1), self.nb_gaussian, axis=-1)\n","        y_t = K.repeat_elements(K.expand_dims(y_t, dim=-1), self.nb_gaussian, axis=-1)\n","\n","        gaussian = 1 / (2 * np.pi * sigma_x * sigma_y + K.epsilon()) * \\\n","                   T.exp(-((x_t - mu_x) ** 2 / (2 * sigma_x ** 2 + K.epsilon()) +\n","                           (y_t - mu_y) ** 2 / (2 * sigma_y ** 2 + K.epsilon())))\n","\n","        gaussian = K.permute_dimensions(gaussian, (2, 0, 1))\n","        max_gauss = K.repeat_elements(K.expand_dims(K.repeat_elements(K.expand_dims(K.max(K.max(gaussian, axis=1), axis=1)), self.height, axis=-1)), self.width, axis=-1)\n","        gaussian = gaussian / max_gauss\n","\n","        output = K.repeat_elements(K.expand_dims(gaussian, dim=0), self.b_s, axis=0)\n","\n","        return output\n","\n","    @staticmethod\n","    def _linspace(start, stop, num):\n","        # produces results identical to:\n","        # np.linspace(start, stop, num)\n","        start = T.cast(start, floatX)\n","        stop = T.cast(stop, floatX)\n","        num = T.cast(num, floatX)\n","        step = (stop - start) / (num - 1)\n","        return T.arange(num, dtype=floatX) * step + start\n","\n","    def get_config(self):\n","        config = {'nb_gaussian': self.nb_gaussian,\n","                  'init': self.init.__name__,\n","                  'W_regularizer': self.W_regularizer.get_config() if self.W_regularizer else None,\n","                  'activity_regularizer': self.activity_regularizer.get_config() if self.activity_regularizer else None,\n","                  'W_constraint': self.W_constraint.get_config() if self.W_constraint else None,\n","                  }\n","        base_config = super(LearningPrior, self).get_config()\n","        return dict(list(base_config.items()) + list(config.items()))"],"metadata":{"id":"ZlULtqSnlJb6","executionInfo":{"status":"ok","timestamp":1640285262161,"user_tz":-330,"elapsed":2,"user":{"displayName":"Diksha Jena (B20CS013)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03488940742474601522"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["from keras import activations\n","\n","class AttentiveConvLSTM(Layer):\n","    def __init__(self, nb_filters_in, nb_filters_out, nb_filters_att, nb_rows, nb_cols,\n","                 init='normal', inner_init='orthogonal', attentive_init='zero',\n","                 activation='tanh', inner_activation='sigmoid',\n","                 W_regularizer=None, U_regularizer=None,\n","                 weights=None, go_backwards=False,\n","                 **kwargs):\n","        self.nb_filters_in = nb_filters_in\n","        self.nb_filters_out = nb_filters_out\n","        self.nb_filters_att = nb_filters_att\n","        self.nb_rows = nb_rows\n","        self.nb_cols = nb_cols\n","        self.init = initializers.get(init)\n","        self.inner_init = initializers.get(inner_init)\n","        self.attentive_init = initializers.get(attentive_init)\n","        self.activation = activations.get(activation)\n","        self.inner_activation = activations.get(inner_activation)\n","        self.initial_weights = weights\n","        self.go_backwards = go_backwards\n","\n","        self.W_regularizer = W_regularizer\n","        self.U_regularizer = U_regularizer\n","        self.input_spec = [InputSpec(ndim=5)]\n","\n","        super(AttentiveConvLSTM, self).__init__(**kwargs)\n","\n","    def get_output_shape_for(self, input_shape):\n","        return input_shape[:1] + (self.nb_filters_out,) + input_shape[3:]\n","\n","    def compute_mask(self, input, mask):\n","        return None\n","\n","    def get_initial_states(self, x):\n","        initial_state = K.sum(x, axis=1)\n","        initial_state = K.conv2d(initial_state, K.zeros((self.nb_filters_out, self.nb_filters_in, 1, 1)), padding='same')\n","        initial_states = [initial_state for _ in range(len(self.states))]\n","\n","        return initial_states\n","\n","    def build(self, input_shape):\n","        self.input_spec = [InputSpec(shape=input_shape)]\n","        self.states = [None, None]\n","        self.trainable_weights = []\n","\n","        self.W_a = Conv2D(self.nb_filters_att, self.nb_rows, self.nb_cols, padding='same', bias=True, init=self.init)\n","        self.U_a = Conv2D(self.nb_filters_att, self.nb_rows, self.nb_cols, padding='same', bias=True, init=self.init)\n","        self.V_a = Conv2D(1, self.nb_rows, self.nb_cols, padding='same', bias=False, init=self.attentive_init)\n","\n","        self.W_a.build((input_shape[0], self.nb_filters_att, input_shape[3], input_shape[4]))\n","        self.U_a.build((input_shape[0], self.nb_filters_in, input_shape[3], input_shape[4]))\n","        self.V_a.build((input_shape[0], self.nb_filters_att, input_shape[3], input_shape[4]))\n","\n","        self.W_a.built = True\n","        self.U_a.built = True\n","        self.V_a.built = True\n","\n","        self.W_i = Conv2D(self.nb_filters_out, self.nb_rows, self.nb_cols, padding='same', bias=True, init=self.init)\n","        self.U_i = Conv2D(self.nb_filters_out, self.nb_rows, self.nb_cols, padding='same', bias=True, init=self.inner_init)\n","\n","        self.W_i.build((input_shape[0], self.nb_filters_in, input_shape[3], input_shape[4]))\n","        self.U_i.build((input_shape[0], self.nb_filters_out, input_shape[3], input_shape[4]))\n","\n","        self.W_i.built = True\n","        self.U_i.built = True\n","\n","        self.W_f = Conv2D(self.nb_filters_out, self.nb_rows, self.nb_cols, padding='same', bias=True, init=self.init)\n","        self.U_f = Conv2D(self.nb_filters_out, self.nb_rows, self.nb_cols, padding='same', bias=True, init=self.inner_init)\n","\n","        self.W_f.build((input_shape[0], self.nb_filters_in, input_shape[3], input_shape[4]))\n","        self.U_f.build((input_shape[0], self.nb_filters_out, input_shape[3], input_shape[4]))\n","\n","        self.W_f.built = True\n","        self.U_f.built = True\n","\n","        self.W_c = Conv2D(self.nb_filters_out, self.nb_rows, self.nb_cols, padding='same', bias=True, init=self.init)\n","        self.U_c = Conv2D(self.nb_filters_out, self.nb_rows, self.nb_cols, padding='same', bias=True, init=self.inner_init)\n","\n","        self.W_c.build((input_shape[0], self.nb_filters_in, input_shape[3], input_shape[4]))\n","        self.U_c.build((input_shape[0], self.nb_filters_out, input_shape[3], input_shape[4]))\n","\n","        self.W_c.built = True\n","        self.U_c.built = True\n","\n","        self.W_o = Conv2D(self.nb_filters_out, self.nb_rows, self.nb_cols, padding='same', bias=True, init=self.init)\n","        self.U_o = Conv2D(self.nb_filters_out, self.nb_rows, self.nb_cols, padding='same', bias=True, init=self.inner_init)\n","\n","        self.W_o.build((input_shape[0], self.nb_filters_in, input_shape[3], input_shape[4]))\n","        self.U_o.build((input_shape[0], self.nb_filters_out, input_shape[3], input_shape[4]))\n","\n","        self.W_o.built = True\n","        self.U_o.built = True\n","\n","        self.trainable_weights = []\n","        self.trainable_weights.extend(self.W_a.trainable_weights)\n","        self.trainable_weights.extend(self.U_a.trainable_weights)\n","        self.trainable_weights.extend(self.V_a.trainable_weights)\n","        self.trainable_weights.extend(self.W_i.trainable_weights)\n","        self.trainable_weights.extend(self.U_i.trainable_weights)\n","        self.trainable_weights.extend(self.W_f.trainable_weights)\n","        self.trainable_weights.extend(self.U_f.trainable_weights)\n","        self.trainable_weights.extend(self.W_c.trainable_weights)\n","        self.trainable_weights.extend(self.U_c.trainable_weights)\n","        self.trainable_weights.extend(self.W_o.trainable_weights)\n","        self.trainable_weights.extend(self.U_o.trainable_weights)\n","\n","    def preprocess_input(self, x):\n","        return x\n","\n","    def step(self, x, states):\n","        x_shape = K.shape(x)\n","        h_tm1 = states[0]\n","        c_tm1 = states[1]\n","\n","        e = self.V_a(K.tanh(self.W_a(h_tm1) + self.U_a(x)))\n","        a = K.reshape(K.softmax(K.batch_flatten(e)), (x_shape[0], 1, x_shape[2], x_shape[3]))\n","        x_tilde = x * K.repeat_elements(a, x_shape[1], 1)\n","\n","        x_i = self.W_i(x_tilde)\n","        x_f = self.W_f(x_tilde)\n","        x_c = self.W_c(x_tilde)\n","        x_o = self.W_o(x_tilde)\n","\n","        i = self.inner_activation(x_i + self.U_i(h_tm1))\n","        f = self.inner_activation(x_f + self.U_f(h_tm1))\n","        c = f * c_tm1 + i * self.activation(x_c + self.U_c(h_tm1))\n","        o = self.inner_activation(x_o + self.U_o(h_tm1))\n","\n","        h = o * self.activation(c)\n","        return h, [h, c]\n","\n","    def get_constants(self, x):\n","        return []\n","\n","    def call(self, x, mask=None):\n","        input_shape = self.input_spec[0].shape\n","        initial_states = self.get_initial_states(x)\n","        constants = self.get_constants(x)\n","        preprocessed_input = self.preprocess_input(x)\n","\n","        last_output, outputs, states = K.rnn(self.step, preprocessed_input,\n","                                             initial_states,\n","                                             go_backwards=False,\n","                                             mask=mask,\n","                                             constants=constants,\n","                                             unroll=False,\n","                                             input_length=input_shape[1])\n","\n","        if last_output.ndim == 3:\n","            last_output = K.expand_dims(last_output, dim=0)\n","\n","        return last_output"],"metadata":{"id":"9vJInszZlb0V","executionInfo":{"status":"ok","timestamp":1640285264108,"user_tz":-330,"elapsed":572,"user":{"displayName":"Diksha Jena (B20CS013)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03488940742474601522"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["def sam_vgg(x):\n","    # Dilated Convolutional Network\n","    dcn = dcn_vgg(input_tensor=x[0])\n","\n","    # Attentive Convolutional LSTM\n","    att_convlstm = Lambda(repeat, repeat_shape)(dcn.output)\n","    att_convlstm = AttentiveConvLSTM(nb_filters_in=512, nb_filters_out=512, nb_filters_att=512,\n","                                     nb_cols=3, nb_rows=3)(att_convlstm)\n","\n","    # Learned Prior (1)\n","    priors1 = LearningPrior(nb_gaussian=16, init=gaussian_priors_init)(x[1])\n","    concateneted = merge([att_convlstm, priors1], mode='concat', concat_axis=1)\n","    learned_priors1 = Conv2D(512, 5, 5, padding='same', activation='relu',\n","                                         dilation_rate=(4, 4))(concateneted)\n","\n","    # Learned Prior (2)\n","    priors2 = LearningPrior(nb_gaussian=16, init=gaussian_priors_init)(x[1])\n","    concateneted = merge([learned_priors1, priors2], mode='concat', concat_axis=1)\n","    learned_priors2 = Conv2D(512, 5, 5, padding='same', activation='relu',\n","                                          dilation_rate=(4, 4))(concateneted)\n","\n","    # Final Convolutional Layer\n","    outs = Conv2D(1, 1, 1, padding='same', activation='relu')(learned_priors2)\n","    outs_up = Lambda(upsampling, upsampling_shape)(outs)\n","\n","    return [outs_up, outs_up, outs_up]\n","\n"],"metadata":{"id":"L22AfStQgjst","executionInfo":{"status":"ok","timestamp":1640285264491,"user_tz":-330,"elapsed":1,"user":{"displayName":"Diksha Jena (B20CS013)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03488940742474601522"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"4YUGBrhtxP89"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["m = Model(input=[x, x_maps], output=sam_vgg([x, x_maps]))          "],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":310},"id":"sBdrZGvHgJD1","executionInfo":{"status":"error","timestamp":1640285773199,"user_tz":-330,"elapsed":401,"user":{"displayName":"Diksha Jena (B20CS013)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03488940742474601522"}},"outputId":"967589f2-b0a1-456e-a2d5-5390954e0b06"},"execution_count":38,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-38-dd10e7353441>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_maps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msam_vgg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_maps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-31-64e05f274448>\u001b[0m in \u001b[0;36msam_vgg\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msam_vgg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Dilated Convolutional Network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdcn_vgg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Attentive Convolutional LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-37-186177f69723>\u001b[0m in \u001b[0;36mdcn_vgg\u001b[0;34m(input_tensor)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'block3_conv2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'block3_conv3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"channels_first\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'block3_pool'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# conv_4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/pooling.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, pool_size, strides, padding, data_format, **kwargs)\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         padding=padding, data_format=data_format, **kwargs)\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/pooling.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, pool_function, pool_size, strides, padding, data_format, name, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m                \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m                name=None, **kwargs):\n\u001b[0;32m--> 337\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPooling2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m       \u001b[0mdata_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, trainable, name, dtype, dynamic, **kwargs)\u001b[0m\n\u001b[1;32m    330\u001b[0m     }\n\u001b[1;32m    331\u001b[0m     \u001b[0;31m# Validate optional keyword arguments.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m     \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowed_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;31m# Mutable properties\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mvalidate_kwargs\u001b[0;34m(kwargs, allowed_kwargs, error_message)\u001b[0m\n\u001b[1;32m   1168\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1170\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: ('Keyword argument not understood:', 'bpadding')"]}]},{"cell_type":"markdown","source":["##check"],"metadata":{"id":"a0LeJYUVxQMi"}},{"cell_type":"code","source":["output=sam_vgg([x, x_maps])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"id":"e43uy12hmcU9","executionInfo":{"status":"error","timestamp":1640288445955,"user_tz":-330,"elapsed":647,"user":{"displayName":"Diksha Jena (B20CS013)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03488940742474601522"}},"outputId":"eb86b234-0e0e-4751-fa31-b8c07aa64922"},"execution_count":65,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-65-e16936250c16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msam_vgg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_maps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-31-64e05f274448>\u001b[0m in \u001b[0;36msam_vgg\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msam_vgg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Dilated Convolutional Network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdcn_vgg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Attentive Convolutional LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-64-3341a6a7d05e>\u001b[0m in \u001b[0;36mdcn_vgg\u001b[0;34m(input_tensor)\u001b[0m\n\u001b[1;32m     50\u001b[0m     weights_path = get_file('vgg16_weights_th_dim_ordering_th_kernels_notop.h5', TH_WEIGHTS_PATH_NO_TOP,\n\u001b[1;32m     51\u001b[0m                             cache_subdir='models')\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Cannot assign value to variable ' block1_conv1/kernel:0': Shape mismatch.The variable shape (3, 3, 320, 64), and the assigned value shape (3, 3, 64, 3) are incompatible."]}]},{"cell_type":"code","source":[""],"metadata":{"id":"KVSNTCHppYrM"},"execution_count":null,"outputs":[]}]}